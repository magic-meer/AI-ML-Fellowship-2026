# Week 5 — Linear Regression

Introduction to Machine Learning and Linear Regression implementation for the AI/ML Fellowship at GDGOC COMSATS Attock.

## Task

### Task 7 - Linear Regression
- Introduction to Machine Learning concepts
- Implement Linear Regression from Scratch:
  - Normal Equation (closed-form solution)
  - Gradient Descent implementation
- Implement Linear Regression using Scikit-Learn
- Model evaluation (MSE, RMSE, MAE, R² Score)
- Multiple Linear Regression

## Concepts Covered
- Machine Learning fundamentals
- Supervised Learning (Regression)
- Linear Regression mathematics
- Normal Equation
- Gradient Descent optimization
- Model evaluation metrics
- Feature scaling impact
- Multiple regression

## Structure
```
Week5-Linear-Regression/
└── Linear_Regression_Task7.ipynb   # Main notebook with all implementations
```

## Key Implementations

### 1. Linear Regression from Scratch (Normal Equation)
- Closed-form solution using matrix operations
- Direct computation: θ = (XᵀX)⁻¹Xᵀy

### 2. Linear Regression from Scratch (Gradient Descent)
- Iterative optimization algorithm
- Learning rate and iteration tuning
- Cost function minimization

### 3. Scikit-Learn Implementation
- Production-ready LinearRegression
- Comparison with custom implementations

## Author
Meher Ali - AI/ML Fellowship, GDGOC COMSATS Attock
